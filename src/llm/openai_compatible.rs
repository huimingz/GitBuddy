use crate::config::ModelParameters;
use crate::llm::{formatter, LLMResult};
use anyhow::{anyhow, Result};
use colored::Colorize;
use regex::Regex;
use serde::{Deserialize, Serialize};
use serde_json::json;
use std::io;
use std::io::{BufRead, BufReader, Write};
use std::time::Duration;

#[derive(Debug)]
pub(crate) struct OpenAICompatible {
    pub(crate) url: String,
    pub(crate) model: String,
    pub(crate) prompt: String,
    pub(crate) api_key: String,
}

#[derive(Debug, Serialize, Deserialize, Default)]
struct OpenAIStreamResponse {
    id: String,
    model: String, // ç”Ÿæˆè¯¥ completion çš„æ¨¡å‹å
    object: String,
    system_fingerprint: Option<String>, // This fingerprint represents the backend configuration that the model runs with.
    choices: Vec<OpenAIStreamChoice>,
    usage: Option<OpenAIResponseUsage>,
    created: i64, // åˆ›å»ºèŠå¤©å®Œæˆæ—¶çš„ Unix æ—¶é—´æˆ³ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
}

#[derive(Debug, Serialize, Deserialize, Default)]
struct OpenAIStreamChoice {
    index: i64,
    delta: OpenAIChoiceDelta,
    finish_reason: Option<String>, // æ¨¡å‹åœæ­¢ç”Ÿæˆ token çš„åŸå› :stop/length/content_filter
}

#[derive(Debug, Serialize, Deserialize, Default)]
struct OpenAIChoiceDelta {
    role: Option<String>,
    content: String,
}

#[derive(Debug, Serialize, Deserialize, Default)]
struct OpenAIResponse {
    id: String,
    model: String, // ç”Ÿæˆè¯¥ completion çš„æ¨¡å‹å
    object: String,
    system_fingerprint: String, // This fingerprint represents the backend configuration that the model runs with.
    choices: Vec<OpenAIResponseChoice>,
    usage: OpenAIResponseUsage, // è¯¥å¯¹è¯è¡¥å…¨è¯·æ±‚çš„ç”¨é‡ä¿¡æ¯
    created: i64,               // åˆ›å»ºèŠå¤©å®Œæˆæ—¶çš„ Unix æ—¶é—´æˆ³ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
}

#[derive(Debug, Serialize, Deserialize)]
struct OpenAIResponseChoice {
    index: i64, // è¯¥ completion åœ¨æ¨¡å‹ç”Ÿæˆçš„ completion çš„é€‰æ‹©åˆ—è¡¨ä¸­çš„ç´¢å¼•ã€‚
    message: OpenAIResponseChoiceMessage,
    finish_reason: String, // æ¨¡å‹åœæ­¢ç”Ÿæˆ token çš„åŸå› :stop/length/content_filter
}

#[derive(Debug, Serialize, Deserialize)]
struct OpenAIResponseChoiceMessage {
    role: String, // è§’è‰²:assistant
    content: String,
}

#[derive(Debug, Serialize, Deserialize, Default)]
struct OpenAIResponseUsage {
    completion_tokens: i64,
    prompt_tokens: i64,
    total_tokens: i64,
}

#[derive(Serialize, Deserialize)]
struct Message {
    #[serde(rename = "role")]
    role: String,
    #[serde(rename = "content")]
    content: String,
}

impl OpenAICompatible {
    pub(crate) fn request(
        &self,
        diff_content: &str,
        option: ModelParameters,
        hint: Option<String>,
    ) -> Result<LLMResult, anyhow::Error> {
        let client = reqwest::blocking::Client::new();

        let api_key = self.api_key.clone();
        let mut messages: Vec<Message> = vec![
            Message {
                role: String::from("system"),
                content: self.prompt.clone(),
            },
            Message {
                role: String::from("user"),
                content: format!("Generate commit message for these changes. If it's a new file, focus on its purpose rather than analyzing its content:\n```diff\n{diff_content}\n```"),
            },
        ];
        if let Some(p) = hint {
            println!("expect prefix: {p}");
            messages.push(Message {
                role: String::from("user"),
                content: format!("hint: {p}"),
            })
        }
        OpenAICompatible::print_configuration(&self.model, diff_content, &option, &self.url);

        let response = client
            .post(&self.url)
            .timeout(Duration::from_secs(120))
            .header("Accept", "text/event-stream")
            .header("Authorization", format!("Bearer {api_key}",))
            .json(&json!({
                "model": &self.model,
                "messages": messages,
                "options": {
                    "temperature": option.temperature,
                    "top_p": option.top_p,
                    "top_k": option.top_k,
                },
                "options": option,
                "keep_alive": "30m",
                "max_tokens": option.max_tokens,
                "stream": true,
            }))
            .send()
            .expect("Error sending request");

        return if response.status().is_success() {
            let mut message = String::new();
            let reader = BufReader::new(response);
            let (start_separator, end_separator) = formatter::get_stream_separator(3); // ä½¿ç”¨æ–¹æ¡ˆ2ï¼Œå¯ä»¥æ”¹ä¸º1æˆ–3å°è¯•å…¶ä»–æ•ˆæœ
            let mut usage = OpenAIResponseUsage::default();
            println!("{}", start_separator);
            for line in reader.lines() {
                let line = line?;
                if line.starts_with("data: ") {
                    let payload = line.trim_start_matches("data: ");
                    if payload == "[DONE]" {
                        break;
                    }

                    // println!("sse data: {}", payload);
                    let data: OpenAIStreamResponse = serde_json::from_str(payload)?;
                    for choice in data.choices {
                        print!("{}", choice.delta.content.cyan());
                        io::stdout().flush()?; // å¼ºåˆ¶åˆ·æ–°åˆ°ç»ˆç«¯ï¼Œç¡®ä¿æ¯æ¬¡æ‰“å°éƒ½æ˜¾ç¤º
                        message.push_str(choice.delta.content.as_str());
                    }
                    if let Some(u) = data.usage {
                        usage.total_tokens += u.total_tokens;
                        usage.prompt_tokens += u.prompt_tokens;
                        usage.completion_tokens += u.completion_tokens;
                    }
                }
            }
            println!("\n{}", end_separator);

            let re = Regex::new(r"(?s)<think>.*?</think>")
                .map_err(|e| format!("invalid regex, err: {e}"))
                .unwrap();
            let message = re.replace_all(&message.trim(), "").trim().to_string();
            let messages = process_llm_response(message.clone())?;

            Ok(LLMResult {
                completion_tokens: usage.completion_tokens,
                prompt_tokens: usage.prompt_tokens,
                total_tokens: usage.total_tokens,
                commit_message: message,
                commit_messages: messages,
            })
        } else {
            let status_code = response.status();
            let reason = match response.text() {
                Ok(text) => text,
                Err(e) => {
                    return Err(anyhow!("Error: {:?}", e.to_string().truncate(100)));
                }
            };
            return Err(anyhow!(
                "Error occurred in request, reason: '{}', status code: {}",
                reason,
                status_code
            ));
        };
    }

    fn print_configuration(model: &String, diff_content: &str, option: &ModelParameters, url: &String) {
        println!(
            "\n{} {} {}",
            "âš™ï¸".bright_cyan(),
            "LLM Configuration".bright_cyan().bold(),
            "ğŸ”®".bright_cyan()
        );
        println!("  {} Model: {}", "ğŸš€".bright_yellow(), model.bright_green().bold());
        println!(
            "  {} Max Tokens: {}",
            "âš¡".bright_yellow(),
            option.max_tokens.to_string().bright_green().bold()
        );
        println!(
            "  {} Temperature: {}",
            "ğŸ²".bright_yellow(),
            option.temperature.to_string().bright_green().bold()
        );
        println!(
            "  {} Top P: {}",
            "ğŸ¯".bright_yellow(),
            option.top_p.to_string().bright_green().bold()
        );
        println!(
            "  {} Diff Length: {} chars",
            "ğŸ“".bright_yellow(),
            diff_content.len().to_string().bright_green().bold()
        );
        println!(
            "  {} Diff Lines: {} lines",
            "ğŸ“‘".bright_yellow(),
            diff_content.lines().count().to_string().bright_green().bold()
        );
        println!("  {} Endpoint: {}\n", "ğŸŒ".bright_yellow(), url.bright_green());
    }
}

fn fix_json_response(text: &str) -> String {
    // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… JSON æ•°ç»„éƒ¨åˆ†
    let re = Regex::new(r"\[\s*\{.*\}\s*\]").unwrap();

    if let Some(json_match) = re.find(text) {
        let json_str = json_match.as_str();

        // æ¸…ç†å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
        let cleaned = json_str
            .replace("\\n", "\n") // å¤„ç†è½¬ä¹‰çš„æ¢è¡Œç¬¦
            .replace("\\\"", "\"") // å¤„ç†è½¬ä¹‰çš„å¼•å·
            .replace("\\\\", "\\") // å¤„ç†è½¬ä¹‰çš„åæ–œæ 
            .replace("\\'", "'"); // å¤„ç†è½¬ä¹‰çš„å•å¼•å·

        // å¤„ç†æ•°ç»„æœ«å°¾çš„å¤šä½™é€—å·
        let comma_fixed = Regex::new(r",(\s*\])").unwrap().replace_all(&cleaned, "$1").to_string();

        // å°è¯•è§£æå’Œé‡æ–°æ ¼å¼åŒ– JSON
        if let Ok(json) = serde_json::from_str::<serde_json::Value>(&comma_fixed) {
            return serde_json::to_string(&json).unwrap_or(comma_fixed);
        }
        comma_fixed
    } else {
        text.to_string()
    }
}

fn extract_json_content(text: &str) -> String {
    // é¦–å…ˆå°è¯•åŒ¹é… ```json
    let json_re = Regex::new(r"```json\s*([\s\S]*?)\s*```").unwrap();
    if let Some(captures) = json_re.captures(text) {
        if let Some(json_content) = captures.get(1) {
            return json_content.as_str().trim().to_string();
        }
    }

    // å¦‚æœæ²¡æ‰¾åˆ° ```jsonï¼Œå°è¯•åŒ¹é…æ™®é€šçš„ ```
    let code_re = Regex::new(r"```\s*([\s\S]*?)\s*```").unwrap();
    if let Some(captures) = code_re.captures(text) {
        if let Some(code_content) = captures.get(1) {
            return code_content.as_str().trim().to_string();
        }
    }

    // å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
    text.to_string()
}

fn process_llm_response(response: String) -> Result<Vec<String>> {
    // é¦–å…ˆå°è¯•æå–ä»£ç å—å†…å®¹
    let content = extract_json_content(&response);

    // å°è¯•ä¿®å¤å’Œè§£æ JSON
    let fixed_json = fix_json_response(&content);

    match serde_json::from_str::<Vec<CommitMessage>>(&fixed_json) {
        Ok(messages) => Ok(messages
            .into_iter()
            .map(|msg| {
                let mut commit = String::new();

                // æ„å»ºæäº¤æ¶ˆæ¯å¤´
                if let Some(scope) = msg.scope.filter(|s| !s.trim().is_empty()) {
                    commit.push_str(&format!("{}({}): {}", msg.r#type, scope.trim(), msg.subject.trim()));
                } else {
                    commit.push_str(&format!("{}: {}", msg.r#type, msg.subject.trim()));
                }

                // æ·»åŠ å¯é€‰çš„æ¶ˆæ¯ä½“
                if let Some(body) = msg.body.filter(|s| !s.trim().is_empty()) {
                    commit.push_str("\n\n");
                    commit.push_str(&formatter::wrap_text(body.trim(), 80));
                }

                // æ·»åŠ å¯é€‰çš„é¡µè„š
                if let Some(footer) = msg.footer.filter(|s| !s.trim().is_empty()) {
                    commit.push_str("\n\n");
                    commit.push_str(&formatter::wrap_text(footer.trim(), 80));
                }

                commit
            })
            .collect()),
        Err(e) => {
            println!("Parse JSON failed: {}", e);
            Err(anyhow::anyhow!("Parse JSON failed: {}", e))
            //  // å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹çš„åˆ†éš”ç¬¦å¤„ç†æ–¹å¼
            //  response
            //  .replace("---", "===")
            //  .replace("___", "===")
            //  .replace("***", "===")
            //  .replace("```", "")
            //  .split("===")
            //  .map(|s| s.trim().to_string())
            //  .filter(|s| !s.is_empty())
            //  .collect()
        }
    }
}

#[derive(Debug, Serialize, Deserialize)]
struct CommitMessage {
    r#type: String,
    scope: Option<String>,
    subject: String,
    body: Option<String>,
    footer: Option<String>,
}
