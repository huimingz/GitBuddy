# Default settings
[default]
# Default AI vendor name (must match a vendor key in the vendors table)
default_vendor = "ollama"
# Request timeout in seconds
timeout = 30

# Custom vendor configurations
# Each vendor is defined as a table under [vendors.name]
[vendors]

# Example: OpenAI-compatible API vendor
[vendors.openai]
api_key = "sk-xxx"
model = "gpt-3.5-turbo"
base_url = "https://api.openai.com/v1"

# Example: DeepSeek vendor
[vendors.deepseek]
api_key = "sk-xxx"
model = "deepseek-chat"
base_url = "https://api.deepseek.com/v1"

# Example: Local Ollama vendor
[vendors.ollama]
api_key = ""
model = "llama2"
base_url = "http://localhost:11434"

# Example: Custom vendor (e.g., self-hosted LLM)
[vendors.custom]
api_key = "your-api-key"
model = "your-model"
base_url = "http://your-llm-server:8000/v1"

# Model parameters for AI response
[model_parameters]
# Controls randomness (0.0-1.0)
temperature = 0.1
# Top-p sampling (0.0-1.0)
top_p = 0.75
# Top-k sampling
top_k = 5
# Maximum tokens in response
max_tokens = 1024
